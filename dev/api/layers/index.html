<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Layers · NeuralGraphPDE.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://YichengDWu.github.io/NeuralGraphPDE.jl/api/layers/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralGraphPDE.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/graph_node/">Neural Graph Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/VMH/">Neural Graph Partial Differential Equations</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li class="is-active"><a class="tocitem" href>Layers</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Docs"><span>Docs</span></a></li></ul></li><li><a class="tocitem" href="../utilities/">Utilities</a></li></ul></li><li><a class="tocitem" href="../../devdoc/">Developer Documentation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href>Layers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Layers</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/main/docs/src/api/layers.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h1><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#NeuralGraphPDE.AbstractGNNContainerLayer"><code>NeuralGraphPDE.AbstractGNNContainerLayer</code></a></li><li><a href="#NeuralGraphPDE.AbstractGNNLayer"><code>NeuralGraphPDE.AbstractGNNLayer</code></a></li><li><a href="#NeuralGraphPDE.ExplicitEdgeConv"><code>NeuralGraphPDE.ExplicitEdgeConv</code></a></li><li><a href="#NeuralGraphPDE.GCNConv"><code>NeuralGraphPDE.GCNConv</code></a></li><li><a href="#NeuralGraphPDE.GNOConv"><code>NeuralGraphPDE.GNOConv</code></a></li><li><a href="#NeuralGraphPDE.MPPDEConv"><code>NeuralGraphPDE.MPPDEConv</code></a></li><li><a href="#NeuralGraphPDE.SpectralConv"><code>NeuralGraphPDE.SpectralConv</code></a></li><li><a href="#NeuralGraphPDE.VMHConv"><code>NeuralGraphPDE.VMHConv</code></a></li></ul><h2 id="Docs"><a class="docs-heading-anchor" href="#Docs">Docs</a><a id="Docs-1"></a><a class="docs-heading-anchor-permalink" href="#Docs" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.AbstractGNNContainerLayer" href="#NeuralGraphPDE.AbstractGNNContainerLayer"><code>NeuralGraphPDE.AbstractGNNContainerLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractGNNContainerLayer &lt;: AbstractExplicitContainerLayer</code></pre><p>This is an abstract type of GNN layers that contains other layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.AbstractGNNLayer" href="#NeuralGraphPDE.AbstractGNNLayer"><code>NeuralGraphPDE.AbstractGNNLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractGNNLayer &lt;: AbstractExplicitLayer</code></pre><p>An abstract type of graph neural networks. See also <a href="#NeuralGraphPDE.AbstractGNNContainerLayer"><code>AbstractGNNContainerLayer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.ExplicitEdgeConv" href="#NeuralGraphPDE.ExplicitEdgeConv"><code>NeuralGraphPDE.ExplicitEdgeConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ExplicitEdgeConv(ϕ; initialgraph = initialgraph, aggr = mean)</code></pre><p>Edge convolutional layer.</p><p class="math-container">\[\mathbf{h}_i&#39; = \square_{j \in N(i)}\, \phi([\mathbf{h}_i, \mathbf{h}_j; \mathbf{x}_j - \mathbf{x}_i])\]</p><p><strong>Arguments</strong></p><ul><li><code>ϕ</code>: A neural network.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: Trainable node embeddings, <code>NamedTuple</code> or <code>Array</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>NamedTuple</code> or <code>Array</code> that has the same struct with <code>x</code> with different a size of channels.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code> where <code>graph.ndata.x</code> represents the spatial coordinates of nodes. You can also put other nontrainable node features in <code>graph.ndata</code> with arbitrary keys. They will be concatenated like <code>u</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">s = [1, 1, 2, 3]
t = [2, 3, 1, 1]
g = GNNGraph(s, t)

u = randn(4, g.num_nodes)
g = GNNGraph(g, ndata = (; x = rand(3, g.num_nodes)))
nn = Dense(4 + 4 + 3 =&gt; 5)
l = ExplicitEdgeConv(nn, initialgraph=g)

rng = Random.default_rng()
ps, st = Lux.setup(rng, l)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L36-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.GCNConv" href="#NeuralGraphPDE.GCNConv"><code>NeuralGraphPDE.GCNConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GCNConv(in_chs::Int, out_chs::Int, activation = identity;
                initialgraph = initialgraph, init_weight = glorot_normal,
                init_bias = zeros32)</code></pre><p>Same as the one in GraphNeuralNetworks.jl but with exiplicit paramters.</p><p><strong>Arguments</strong></p><ul><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># create data
s = [1,1,2,3]
t = [2,3,1,1]
g = GNNGraph(s, t)
x = randn(3, g.num_nodes)

# create layer
l = GCNConv(3 =&gt; 5, initialgraph = g)

# setup layer
rng = Random.default_rng()
Random.seed!(rng, 0)

ps, st = Lux.setup(rng, l)

# forward pass
y = l(x, ps, st)       # size:  5 × num_nodes</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L114-L146">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.GNOConv" href="#NeuralGraphPDE.GNOConv"><code>NeuralGraphPDE.GNOConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GNOConv(in_chs =&gt; out_chs, ϕ; initialgraph = initialgraph, aggr = mean, bias = true)</code></pre><p>Convolutional layer from <a href="https://openreview.net/forum?id=5fbUEUTZEn7">Neural Operator: Graph Kernel Network for Partial Differential Equations</a>.</p><p class="math-container">\[\begin{aligned}
	\mathbf{m}_i&amp;=\Box _{j\in N(i)}\,\phi (\mathbf{a}_i,\mathbf{a}_j,\mathbf{x}_i,\mathbf{x}_j)\mathbf{h}_j\\
	\mathbf{h}_i&#39;&amp;=\,\,\sigma \left( \mathbf{Wh}_i+\mathbf{m}_i+\mathbf{b} \right)\\
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>in_chs</code>: Number of input channels.</li><li><code>out_chs</code>: Number of output channels.</li><li><code>ϕ</code>: Neural network for the message function. The output size of <code>ϕ</code> should be <code>in_chs * out_chs</code>.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li><li><code>bias</code>: Whether to add bias to the output.</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: <code>Array</code> of the size <code>(in_chs, num_nodes)</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Array</code> of the size <code>(out_chs, num_nodes)</code>.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li><li><code>W</code>.</li><li><code>b</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code>. All features are stored in either <code>graph.ndata</code> or <code>graph.edata</code>. They will be concatenated and then fed into <code>ϕ</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">g = rand_graph(10, 6)

g = GNNGraph(g, ndata = (; a = rand(2, 10), x = rand(3, 10)))
in_chs, out_chs = 5, 7
h = randn(in_chs, 10)
ϕ = Dense(2 + 2 + 3 + 3 =&gt; in_chs * out_chs)
l = GNOConv(5 =&gt; 7, ϕ, initialgraph = g)

rng = Random.default_rng()
ps, st = Lux.setup(rng, l)

y, st = l(h, ps, st)

#edge features
e = rand(2 + 2 + 3 + 3, 6)
g = GNNGraph(g, edata = e)
st = updategraph(st, g)
y, st = l(h, ps, st)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L424-L484">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.MPPDEConv" href="#NeuralGraphPDE.MPPDEConv"><code>NeuralGraphPDE.MPPDEConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPPDEConv(ϕ, ψ; initialgraph = initialgraph, aggr = mean, local_features = (:u, :x))</code></pre><p>Convolutional layer from <a href="https://arxiv.org/abs/2202.03376">Message Passing Neural PDE Solvers</a>, without the temporal bulking trick.</p><p class="math-container">\[\begin{aligned}
	\mathbf{m}_i&amp;=\Box _{j\in N(i)}\,\phi (\mathbf{h}_i,\mathbf{h}_j;\mathbf{u}_i-\mathbf{u}_j;\mathbf{x}_i-\mathbf{x}_j;\theta )\\
	\mathbf{h}_i&#39;&amp;=\psi (\mathbf{h}_i,\mathbf{m}_i,\theta )\\
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>ϕ</code>: The neural network for the message function.</li><li><code>ψ</code>: The neural network for the update function.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: Trainable node embeddings, <code>Array</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>NamedTuple</code> or <code>Array</code> that has the same struct with <code>x</code> with different a size of channels.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li><li>Parameters of <code>ψ</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code> for which <code>graph.gdata</code> represents the graph level features of the underlying PDE. All features in <code>graph.gdata</code>   should be a matrices of the size <code>(num_feats, num_graphs)</code>. You can store <code>u</code>(<code>x</code>) in <code>graph.ndata</code> or <code>u_j-u_i</code>(<code>x_jx_i</code>) in <code>graph.edata</code>.   If <code>g</code> is a batched graph, then currently all graphs need to have the same structure. Note that <code>t</code> is included in <code>graph.gdata</code>   in the original paper.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">g = rand_graph(10, 6)
g = GNNGraph(g, ndata = (; u = rand(2, 10), x = rand(3, 10)), gdata = (; θ = rand(4)))
h = randn(5, 10)
ϕ = Dense(5 + 5 + 2 + 3 + 4 =&gt; 5)
ψ = Dense(5 + 5 + 4 =&gt; 7)
l = MPPDEConv(ϕ, ψ, initialgraph = g)
rng = Random.default_rng()
ps, st = Lux.setup(rng, l)
y, st = l(h, ps, st)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L334-L376">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.SpectralConv" href="#NeuralGraphPDE.SpectralConv"><code>NeuralGraphPDE.SpectralConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SpectralConv(n::Int)</code></pre><p>Compute the Fourier differentiation of a 1D periodic function evenly sampled on <span>$[0,2π]$</span>, not including one of the endpoints. This is only a toy function and not the most effecient approch.</p><p class="math-container">\[    u_i =\frac{1}{2} \sum_{j}{\cos \left(\frac{\left(x_{i}-x_{j}\right) n}{2}\right) \cot \left(\frac{x_{i}-x_{j}}{2}\right) u_{j}}\]</p><p><strong>Arguments</strong></p><ul><li><code>n</code>: The number of sampled points.</li></ul><p><strong>Inputs</strong></p><ul><li><code>u</code>: Discret function values on <span>$2jπ/n$</span>, for <span>$j=1,2,...,n$</span>.</li></ul><p><strong>Returns</strong></p><ul><li>The derivative of <code>u</code>.</li></ul><p><strong>Parameters</strong></p><ul><li>None.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: A comple graph <code>g</code> of the type <code>GNNGraph</code>, where <code>g.edata.e</code> is <code>x_i-x_j</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; using Lux, Random

julia&gt; s = SpectralConv(100);

julia&gt; rng = Random.default_rng();
julia&gt; ps, st = Lux.setup(rng, s);

julia&gt; x = LinRange(0, 2π, 101)[2:end];
julia&gt; s(sin.(x), ps, st)[1] .- cos.(x)
100-element Vector{Float64}:
 -2.9976021664879227e-15
  4.440892098500626e-15
 -3.885780586188048e-15
  4.9960036108132044e-15
 -1.1102230246251565e-15
 -6.328271240363392e-15
  6.994405055138486e-15
  5.551115123125783e-16
  0.0
  ⋮
 -1.892930256985892e-13
  1.8640644583456378e-13
 -1.2012613126444194e-13
  8.526512829121202e-14
 -6.405986852087153e-14
  4.451994328746878e-14
 -2.631228568361621e-14
  1.509903313490213e-14

julia&gt; s(cos.(x), ps, st)[1] .+ sin.(x)
100-element Vector{Float64}:
  1.9442780718748054e-14
 -3.552713678800501e-14
  4.246603069191224e-15
 -8.715250743307479e-15
  1.1934897514720433e-14
 -2.7533531010703882e-14
  2.6867397195928788e-14
 -1.176836406102666e-14
  6.5503158452884236e-15
  ⋮
  4.048983370807946e-13
 -4.0362158060247566e-13
  2.742805982336449e-13
 -2.53408405370692e-13
  2.479405569744131e-13
 -2.366440376988521e-13
  2.0448920334814602e-13
 -6.064106189943799e-14</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L549-L632">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.VMHConv" href="#NeuralGraphPDE.VMHConv"><code>NeuralGraphPDE.VMHConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">VMHConv(ϕ, γ; initialgraph = initialgraph, aggr = mean)</code></pre><p>Convolutional layer from <a href="https://arxiv.org/abs/2006.08956">Learning continuous-time PDEs from sparse data with graph neural networks</a>.</p><p class="math-container">\[\begin{aligned}
\mathbf{m}_i &amp;= \square_{j \in N(i)}\, \phi(\mathbf{h}_i, \mathbf{h}_j - \mathbf{h}_i; \mathbf{x}_j - \mathbf{x}_i)\\
\mathbf{h}_i&#39; &amp;= \gamma(\mathbf{h}_i ,\mathbf{m}_i)
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>ϕ</code>: The neural network for the message function.</li><li><code>γ</code>: The neural network for the update function.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: Trainable node embeddings, <code>NamedTuple</code> or <code>Array</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>NamedTuple</code> or <code>Array</code> that has the same struct with <code>x</code> with different a size of channels.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li><li>Parameters of <code>γ</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code> where <code>graph.ndata.x</code> represents the spatial coordinates of nodes.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">s = [1, 1, 2, 3]
t = [2, 3, 1, 1]
g = GNNGraph(s, t)

u = randn(4, g.num_nodes)
g = GNNGraph(g, ndata = (; x = rand(3, g.num_nodes)))
ϕ = Dense(4 + 4 + 3 =&gt; 5)
γ = Dense(5 + 4 =&gt; 7)
l = VMHConv(ϕ, γ, initialgraph = g)

rng = Random.default_rng()
ps, st = Lux.setup(rng, l)

y, st = l(u, ps, st)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/NeuralGraphPDE.jl/blob/4cdc18e9858c1152265b995fdb891135cb626bd8/src/layers.jl#L241-L294">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../tutorials/VMH/">« Neural Graph Partial Differential Equations</a><a class="docs-footer-nextpage" href="../utilities/">Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 8 June 2023 03:05">Thursday 8 June 2023</span>. Using Julia version 1.9.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
