<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Developer Documentation · NeuralGraphPDE.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://MilkshakeForReal.github.io/NeuralGraphPDE.jl/devdoc/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">NeuralGraphPDE.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/graph_node/">Neural Graph Ordinary Differential Equations</a></li><li><a class="tocitem" href="../tutorials/VMH/">Neural Graph Partial Differential Equations</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="../api/layers/">Layers</a></li><li><a class="tocitem" href="../api/utilities/">Utilities</a></li></ul></li><li class="is-active"><a class="tocitem" href>Developer Documentation</a><ul class="internal"><li><a class="tocitem" href="#AbstractGNNLayer"><span>AbstractGNNLayer</span></a></li><li><a class="tocitem" href="#AbstractExplicitContainerLayer"><span>AbstractExplicitContainerLayer</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Developer Documentation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Developer Documentation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/main/docs/src/devdoc.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Implementing-custom-layers"><a class="docs-heading-anchor" href="#Implementing-custom-layers">Implementing custom layers</a><a id="Implementing-custom-layers-1"></a><a class="docs-heading-anchor-permalink" href="#Implementing-custom-layers" title="Permalink"></a></h1><p><code>NeuralGraphPDE</code> basically share the same interface with <code>Lux.jl</code>. You may want to take a look at its <a href="http://lux.csail.mit.edu/dev/manual/migrate_from_flux/#implementing-custom-layers">doc</a> first. Based on that, <code>NeuralGraphPDE</code> provides two abstract types, <code>AbstractGNNLayer</code> and <code>AbstractGNNContainerLayer</code>, they are subtypes of <code>AbstractExplicitLayer</code> and <code>AbstractExplicitContainerLayer</code>, respectively. You should subtype your custom layers to them.</p><h2 id="AbstractGNNLayer"><a class="docs-heading-anchor" href="#AbstractGNNLayer">AbstractGNNLayer</a><a id="AbstractGNNLayer-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractGNNLayer" title="Permalink"></a></h2><p>You can define a custom layer with the following steps:</p><p>Step 1. Define your type of the layer and add <code>initialgraph</code> as a field.</p><pre><code class="nohighlight hljs">struct MyGNNLayer &lt;: AbstractGNNLayer
    initialgraph::Function
    ...
end</code></pre><p>Step 2. Define <code>initialparameters</code> as in <code>Lux</code>. The default <code>initialstates</code> returns <code>(graph = GNNGraph(...))</code>, so this is optional. If you want to put more things in <code>st</code> then you need to overload <code>initialstates</code> as well.</p><pre><code class="language-julia hljs">function initialstates(rng::AbstractRNG, l::AbstractGNNLayer)
    (graph = l.initialgraph(), otherstates)
end</code></pre><p>In this case, it is recommended to also overload <code>statelength</code>, it should be like</p><pre><code class="language-julia hljs">statelength(l::AbstractGNNLayer) = 1 + length(otherstates) # 1 for the graph</code></pre><p>Step 3. Define the constructor(s) that has the keyword argument <code>initialgraph=initialgraph</code>.</p><pre><code class="nohighlight hljs">function MyGNNLayer(...; initialgraph=initialgraph)
  initalgraph = wrapgraph(initialgraph) # always wrap initialgraph so the input can be a graph or a function
  MyGNNLayer{...}(initialgraph,...)
end</code></pre><p>Step 4. Define the forward pass. Keep in mind that the graph is stored in <code>st</code>. It is recommended to store nontrainable node features in the graph.</p><pre><code class="nohighlight hljs">function (l::MyGNNLayer)(x,ps,st)
    g = st.graph
    s = g.ndata # nontrainable node features, if there is any
    function message(xi, xj, e)
        ...
        return m
    end
    xs = merge(x, s) # assuming x is a named tuple
    return propagte(message, g, l.aggr, xi = xs, xj = xs), st
end</code></pre><h2 id="AbstractExplicitContainerLayer"><a class="docs-heading-anchor" href="#AbstractExplicitContainerLayer">AbstractExplicitContainerLayer</a><a id="AbstractExplicitContainerLayer-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractExplicitContainerLayer" title="Permalink"></a></h2><p>You should only subtype your layer to <code>AbstractExplicitContainerLayer</code> then</p><ol><li>you need to write a custom message function, and</li><li>the layer contains other layers.</li></ol><p>For the most part it will look identical to defining <code>AbstractGNNLayer</code>. You just need to treat the message function more carefully.</p><pre><code class="nohighlight hljs">function message(xi, xj, e)
        ...
        m, st.nn = nn(..., st.nn)
        st = merge(st, (nn = st_nn,))
        return m
end</code></pre><p>Note that if you have only one neural layer insider a <code>AbstractExplicitContainerLayer</code>, then the parameters will be reduced but not the states.</p><pre><code class="language-julia hljs">julia&gt; l = ExplicitEdgeConv(nn, initialgraph = g)

julia&gt; rng = Random.default_rng()

julia&gt; ps, st = Lux.setup(rng, l)

julia&gt; ps
(weight = Float32[0.22180015 -0.09448394 … -0.41880473 -0.49083555; -0.23709725 0.05150031 … 0.48641983 0.14893274; … ; 0.42824164 0.5589718 … -0.5763395 0.18395355; 0.25994122 0.22801241 … 0.59201854 0.3832495], bias = Float32[0.0; 0.0; … ; 0.0; 0.0;;])

julia&gt; st
(ϕ = NamedTuple(), graph = GNNGraph(3, 4))</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/utilities/">« Utilities</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Sunday 3 July 2022 00:28">Sunday 3 July 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
