<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Layers · NeuralGraphPDE.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://MilkshakeForReal.github.io/NeuralGraphPDE.jl/api/layers/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralGraphPDE.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/graph_node/">Neural Graph Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/VMH/">Neural Graph Partial Differential Equations</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li class="is-active"><a class="tocitem" href>Layers</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Docs"><span>Docs</span></a></li></ul></li><li><a class="tocitem" href="../utilities/">Utilities</a></li></ul></li><li><a class="tocitem" href="../../devdoc/">Developer Documentation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href>Layers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Layers</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/main/docs/src/api/layers.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h1><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#NeuralGraphPDE.AbstractGNNContainerLayer"><code>NeuralGraphPDE.AbstractGNNContainerLayer</code></a></li><li><a href="#NeuralGraphPDE.AbstractGNNLayer"><code>NeuralGraphPDE.AbstractGNNLayer</code></a></li><li><a href="#NeuralGraphPDE.ExplicitEdgeConv"><code>NeuralGraphPDE.ExplicitEdgeConv</code></a></li><li><a href="#NeuralGraphPDE.ExplicitGCNConv"><code>NeuralGraphPDE.ExplicitGCNConv</code></a></li><li><a href="#NeuralGraphPDE.GNOConv"><code>NeuralGraphPDE.GNOConv</code></a></li><li><a href="#NeuralGraphPDE.MPPDEConv"><code>NeuralGraphPDE.MPPDEConv</code></a></li><li><a href="#NeuralGraphPDE.VMHConv"><code>NeuralGraphPDE.VMHConv</code></a></li></ul><h2 id="Docs"><a class="docs-heading-anchor" href="#Docs">Docs</a><a id="Docs-1"></a><a class="docs-heading-anchor-permalink" href="#Docs" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.AbstractGNNContainerLayer" href="#NeuralGraphPDE.AbstractGNNContainerLayer"><code>NeuralGraphPDE.AbstractGNNContainerLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractGNNContainerLayer &lt;: AbstractExplicitContainerLayer</code></pre><p>This is an abstract type of GNN layers that contains other layers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.AbstractGNNLayer" href="#NeuralGraphPDE.AbstractGNNLayer"><code>NeuralGraphPDE.AbstractGNNLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractGNNLayer &lt;: AbstractExplicitLayer</code></pre><p>An abstract type of graph neural networks. See also <a href="#NeuralGraphPDE.AbstractGNNContainerLayer"><code>AbstractGNNContainerLayer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L1-L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.ExplicitEdgeConv" href="#NeuralGraphPDE.ExplicitEdgeConv"><code>NeuralGraphPDE.ExplicitEdgeConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ExplicitEdgeConv(ϕ; initialgraph = initialgraph, aggr = mean)</code></pre><p>Edge convolutional layer.</p><p class="math-container">\[\mathbf{h}_i&#39; = \square_{j \in N(i)}\, \phi([\mathbf{h}_i, \mathbf{h}_j; \mathbf{x}_j - \mathbf{x}_i])\]</p><p><strong>Arguments</strong></p><ul><li><code>ϕ</code>: A neural network. </li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: Trainable node embeddings, <code>NamedTuple</code> or <code>Array</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>NamedTuple</code> or <code>Array</code> that has the same struct with <code>x</code> with different a size of channels.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code> where <code>graph.ndata.x</code> represents the spatial coordinates of nodes. You can also put other nontrainable node features in <code>graph.ndata</code> with arbitrary keys. They will be concatenated like <code>u</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">s = [1, 1, 2, 3]
t = [2, 3, 1, 1]
g = GNNGraph(s, t)

u = randn(4, g.num_nodes)
g = GNNGraph(g, ndata = (; x = rand(3, g.num_nodes)))
nn = Dense(4 + 4 + 3 =&gt; 5)
l = ExplicitEdgeConv(nn, initialgraph=g)

rng = Random.default_rng()
ps, st = Lux.setup(rng, l)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L35-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.ExplicitGCNConv" href="#NeuralGraphPDE.ExplicitGCNConv"><code>NeuralGraphPDE.ExplicitGCNConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ExplicitGCNConv(in_chs::Int, out_chs::Int, activation = identity;
                initialgraph = initialgraph, init_weight = glorot_normal,
                init_bias = zeros32)</code></pre><p>Same as the one in GraphNeuralNetworks.jl but with exiplicit paramters.</p><p><strong>Arguments</strong></p><ul><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># create data
s = [1,1,2,3]
t = [2,3,1,1]
g = GNNGraph(s, t)
x = randn(3, g.num_nodes)

# create layer
l = ExplicitGCNConv(3 =&gt; 5, initialgraph = g) 

# setup layer
rng = Random.default_rng()
Random.seed!(rng, 0)

ps, st = Lux.setup(rng, l)

# forward pass
y = l(x, ps, st)       # size:  5 × num_nodes</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L115-L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.GNOConv" href="#NeuralGraphPDE.GNOConv"><code>NeuralGraphPDE.GNOConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GNOConv(in_chs =&gt; out_chs, ϕ; initialgraph = initialgraph, aggr = mean, bias = true)</code></pre><p>Convolutional layer from <a href="https://openreview.net/forum?id=5fbUEUTZEn7">Neural Operator: Graph Kernel Network for Partial Differential Equations</a>. </p><p class="math-container">\[\begin{aligned}
	\mathbf{m}_i&amp;=\Box _{j\in N(i)}\,\phi (\mathbf{a}_i,\mathbf{a}_j,\mathbf{x}_i,\mathbf{x}_j)\mathbf{h}_j\\
	\mathbf{h}_i&#39;&amp;=\,\,\sigma \left( \mathbf{Wh}_i+\mathbf{m}_i+\mathbf{b} \right)\\
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>in_chs</code>: Number of input channels.</li><li><code>out_chs</code>: Number of output channels.</li><li><code>ϕ</code>: Neural network for the message function. The output size of <code>ϕ</code> should be <code>in_chs * out_chs</code>.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li><li><code>bias</code>: Whether to add bias to the output.</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: <code>Array</code> of the size <code>(in_chs, num_nodes)</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>Array</code> of the size <code>(out_chs, num_nodes)</code>.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li><li><code>W</code>.</li><li><code>b</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code>. All features are stored in either <code>graph.ndata</code> or <code>graph.edata</code>. They will be concatenated and then fed into <code>ϕ</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">g = rand_graph(10, 6)

g = GNNGraph(g, ndata = (; a = rand(2, 10), x = rand(3, 10)))
in_chs, out_chs = 5, 7
h = randn(in_chs, 10)
ϕ = Dense(2 + 2 + 3 + 3 =&gt; in_chs * out_chs)
l = GNOConv(5 =&gt; 7, ϕ, initialgraph = g)

rng = Random.default_rng()
ps, st = Lux.setup(rng, l)

y, st = l(h, ps, st)

#edge features
e = rand(2 + 2 + 3 + 3, 6)
g = GNNGraph(g, edata = e)
st = updategraph(st, g)
y, st = l(h, ps, st)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L421-L481">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.MPPDEConv" href="#NeuralGraphPDE.MPPDEConv"><code>NeuralGraphPDE.MPPDEConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPPDEConv(ϕ, ψ; initialgraph = initialgraph, aggr = mean, local_features = (:u, :x))</code></pre><p>Convolutional layer from <a href="https://arxiv.org/abs/2202.03376">Message Passing Neural PDE Solvers</a>, without the temporal bulking trick. </p><p class="math-container">\[\begin{aligned}
	\mathbf{m}_i&amp;=\Box _{j\in N(i)}\,\phi (\mathbf{h}_i,\mathbf{h}_j;\mathbf{u}_i-\mathbf{u}_j;\mathbf{x}_i-\mathbf{x}_j;\theta )\\
	\mathbf{h}_i&#39;&amp;=\psi (\mathbf{h}_i,\mathbf{m}_i,\theta )\\
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>ϕ</code>: The neural network for the message function. </li><li><code>ψ</code>: The neural network for the update function.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li><li><code>local_features</code>: The features that will be differentiated in the message function. </li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: Trainable node embeddings, <code>Array</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>NamedTuple</code> or <code>Array</code> that has the same struct with <code>x</code> with different a size of channels.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li><li>Parameters of <code>ψ</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code> where <code>graph.ndata.x</code> represents the spatial coordinates of nodes, <code>graph.ndata.u</code> represents the initial condition, and <code>graph.gdata.θ</code> represents the graph level features of the underlying PDE. <code>θ</code> should be a matrix</li></ul><p>of the size <code>(num_feats, num_graphs)</code>. If <code>g</code> is a batched graph, then all graphs need to have the same structure.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">g = rand_graph(10, 6)
g = GNNGraph(g, ndata = (; u = rand(2, 10), x = rand(3, 10)), gdata = (; θ = rand(4)))
h = randn(5, 10)
ϕ = Dense(5 + 5 + 2 + 3 + 4 =&gt; 5)
ψ = Dense(5 + 5 + 4 =&gt; 7)
l = MPPDEConv(ϕ, ψ, initialgraph = g)
rng = Random.default_rng()
ps, st = Lux.setup(rng, l)
y, st = l(h, ps, st)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L338-L375">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralGraphPDE.VMHConv" href="#NeuralGraphPDE.VMHConv"><code>NeuralGraphPDE.VMHConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">VMHConv(ϕ, γ; initialgraph = initialgraph, aggr = mean)</code></pre><p>Convolutional layer from <a href="https://arxiv.org/abs/2006.08956">Learning continuous-time PDEs from sparse data with graph neural networks</a>.</p><p class="math-container">\[\begin{aligned}
\mathbf{m}_i &amp;= \square_{j \in N(i)}\, \phi(\mathbf{h}_i, \mathbf{h}_j - \mathbf{h}_i; \mathbf{x}_j - \mathbf{x}_i)\\
\mathbf{h}_i&#39; &amp;= \gamma(\mathbf{h}_i ,\mathbf{m}_i)
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>ϕ</code>: The neural network for the message function. </li><li><code>γ</code>: The neural network for the update function.</li><li><code>initialgraph</code>: <code>GNNGraph</code> or a function that returns a <code>GNNGraph</code></li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li></ul><p><strong>Inputs</strong></p><ul><li><code>h</code>: Trainable node embeddings, <code>NamedTuple</code> or <code>Array</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>NamedTuple</code> or <code>Array</code> that has the same struct with <code>x</code> with different a size of channels.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of <code>ϕ</code>.</li><li>Parameters of <code>γ</code>.</li></ul><p><strong>States</strong></p><ul><li><code>graph</code>: <code>GNNGraph</code> where <code>graph.ndata.x</code> represents the spatial coordinates of nodes.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">s = [1, 1, 2, 3]
t = [2, 3, 1, 1]
g = GNNGraph(s, t)

u = randn(4, g.num_nodes)
g = GNNGraph(g, ndata = (; x = rand(3, g.num_nodes)))
ϕ = Dense(4 + 4 + 3 =&gt; 5)
γ = Dense(5 + 4 =&gt; 7)
l = VMHConv(ϕ, γ, initialgraph = g)

rng = Random.default_rng()
ps, st = Lux.setup(rng, l)

y, st = l(u, ps, st)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/NeuralGraphPDE.jl/blob/f0edb41874dd0b4788a4ec1213eed5308611dc5d/src/layers.jl#L244-L297">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../tutorials/VMH/">« Neural Graph Partial Differential Equations</a><a class="docs-footer-nextpage" href="../utilities/">Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Monday 4 July 2022 20:25">Monday 4 July 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
